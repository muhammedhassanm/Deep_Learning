{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All models : https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\n",
    "\n",
    "CNN Text Classification\n",
    "https://github.com/cmasch/cnn-text-classification/blob/master/Evaluation.ipynb\n",
    "\n",
    "CNN Multichannel Text Classification + Hierarchical attention + ...\n",
    "https://github.com/gaurav104/TextClassification/blob/master/CNN%20Multichannel%20Text%20Classification.ipynb\n",
    "\n",
    "Notes for Deep Learning\n",
    "https://arxiv.org/pdf/1808.09772.pdf\n",
    "\n",
    "Doc classification with NLP\n",
    "https://github.com/mdh266/DocumentClassificationNLP/blob/master/NLP.ipynb\n",
    "\n",
    "Paragraph Topic Classification\n",
    "http://cs229.stanford.edu/proj2016/report/NhoNg-ParagraphTopicClassification-report.pdf\n",
    "\n",
    "1D convolutional neural networks for NLP\n",
    "https://github.com/Tixierae/deep_learning_NLP/blob/master/cnn_imdb.ipynb\n",
    "\n",
    "Hierarchical Attention for text classification\n",
    "https://github.com/Tixierae/deep_learning_NLP/blob/master/HAN/HAN_final.ipynb\n",
    "\n",
    "Multi-class classification scikit learn (Random forest, SVM, logistic regression)\n",
    "https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f\n",
    "https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "\n",
    "Text feature extraction TFIDF mathematics\n",
    "https://dzone.com/articles/machine-learning-text-feature-0\n",
    "\n",
    "Classification Yelp Reviews (AWS)\n",
    "http://www.developintelligence.com/blog/2017/06/practical-neural-networks-keras-classifying-yelp-reviews/\n",
    "\n",
    "Convolutional Neural Networks for Text Classification (waouuuuu)\n",
    "http://www.davidsbatista.net/blog/2018/03/31/SentenceClassificationConvNets/\n",
    "https://github.com/davidsbatista/ConvNets-for-sentence-classification\n",
    "\n",
    "\n",
    "**3 ways to interpretate your NLP model** [Lime, ELI5, Skater]\n",
    "https://github.com/makcedward/nlp/blob/master/sample/nlp-model_interpretation.ipynb\n",
    "https://towardsdatascience.com/3-ways-to-interpretate-your-nlp-model-to-management-and-customer-5428bc07ce15\n",
    "https://medium.freecodecamp.org/how-to-improve-your-machine-learning-models-by-explaining-predictions-with-lime-7493e1d78375\n",
    "\n",
    "Deep Learning for text made easy with AllenNLP\n",
    "https://medium.com/swlh/deep-learning-for-text-made-easy-with-allennlp-62bc79d41f31\n",
    "\n",
    "Ensemble Classifiers\n",
    "https://www.learndatasci.com/tutorials/predicting-reddit-news-sentiment-naive-bayes-text-classifiers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adsieg\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "#from keras.preprocessing import text, sequence\n",
    "#from keras import layers, models, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='BLUE'>DATA LOADING </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. FIRST dataset: Consumer Reviews [Amazon] [2 labels / binary classification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = open('corpus.txt', encoding=\"utf8\").read()\n",
    "labels, texts = [], []\n",
    "for i, line in enumerate(data.split(\"\\n\")):\n",
    "    content = line.split()\n",
    "    labels.append(content[0])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "# create a dataframe using texts and lables\n",
    "trainDF = pandas.DataFrame()\n",
    "trainDF['text'] = texts\n",
    "trainDF['label'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(trainDF['text'], trainDF['label'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Second dataset: Consumer Complaints [Banking industry] [multi-classification]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:/Users/adsieg/Desktop/link_news/ML/Consumer_Complaints.csv')\n",
    "df.head()\n",
    "\n",
    "df = df[pd.notnull(df['Consumer complaint narrative'])]\n",
    "\n",
    "col = ['Product', 'Consumer complaint narrative']\n",
    "df = df[col]\n",
    "df.columns = ['Product', 'Consumer_complaint_narrative']\n",
    "\n",
    "df['category_id'] = df['Product'].factorize()[0]\n",
    "from io import StringIO\n",
    "category_id_df = df[['Product', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'Product']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer_complaint_narrative</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>An account on my credit report has a mistaken ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>This company refuses to provide me verificatio...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>This complaint is in regards to Square Two Fin...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Product                       Consumer_complaint_narrative  \\\n",
       "1   Credit reporting  I have outdated information on my credit repor...   \n",
       "2      Consumer Loan  I purchased a new car on XXXX XXXX. The car de...   \n",
       "7   Credit reporting  An account on my credit report has a mistaken ...   \n",
       "12   Debt collection  This company refuses to provide me verificatio...   \n",
       "16   Debt collection  This complaint is in regards to Square Two Fin...   \n",
       "\n",
       "    category_id  \n",
       "1             0  \n",
       "2             1  \n",
       "7             0  \n",
       "12            2  \n",
       "16            2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We take only 10,000 customer complaints to speed up algorithms\n",
    "df = df[:10000]\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An account on my credit report has a mistaken date. I mailed in a debt validation letter to allow XXXX to correct the information. I received a letter in the mail, stating that Experian received my correspondence and found it to be \" suspicious \\'\\' and that \" I did n\\'t write it \\'\\'. Experian \\'s letter is worded to imply that I am incapable of writing my own letter. I was deeply offended by this implication. \\nI called Experian to figure out why my letter was so suspicious. I spoke to a representative who was incredibly unhelpful, She did not effectively answer any questions I asked of her, and she kept ignoring what I was saying regarding the offensive letter and my dispute process. I feel the representative did what she wanted to do, and I am not satisfied. It is STILL not clear to me why I received this letter. I typed this letter, I signed this letter, and I paid to mail this letter, yet Experian willfully disregarded my lawful request. \\nI am disgusted with this entire situation, and I would like for my dispute to be handled appropriately, and I would like for an Experian representative to contact me and give me a real explanation for this letter.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Consumer_complaint_narrative'].iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conventional algorithms are often **biased towards the majority class**, not taking the data distribution into consideration. In the worst case, **minority classes are treated as outliers and ignored**. \n",
    "\n",
    "For some cases, such as fraud detection or cancer prediction, we would need to carefully configure our model or artificially balance the dataset, for example by **undersampling or oversampling each class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "df.groupby('Product').Consumer_complaint_narrative.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='BLUE'>DATA CLEANING</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. --- A quick and easy function to clean my text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def preprocess(raw_text):\n",
    "\n",
    "    # keep only words\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "\n",
    "    # convert to lower case and split \n",
    "    words = letters_only_text.lower().split()\n",
    "\n",
    "    # remove stopwords\n",
    "    stopword_set = set(stopwords.words(\"english\"))\n",
    "    meaningful_words = [w for w in words if w not in stopword_set]\n",
    "    \n",
    "    #stemmed words\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_words = [ps.stem(word) for word in meaningful_words]\n",
    "    \n",
    "    #join the cleaned words in a list\n",
    "    cleaned_word_list = \" \".join(stemmed_words)\n",
    "\n",
    "    return cleaned_word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Consumer_complaint_narrative'] = df['Consumer_complaint_narrative'].apply(lambda line : preprocess(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. How to decline all ways of a given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def split_dataset_into_words(dataset):\n",
    "    datawords = dataset.apply(lambda x: x.split())\n",
    "    return list(datawords)\n",
    "\n",
    "#  my_list = all_incidents \n",
    "# dictionnary\n",
    "def buffer_stemmisation_keywords(my_list):\n",
    "    my_list = [item for sublist in my_list for item in sublist]\n",
    "    aux = pd.DataFrame(my_list, columns =['word'] )\n",
    "    aux['word_stemmed'] = aux['word'].apply(lambda x : stemmer.stem(x))\n",
    "    aux = aux.groupby('word_stemmed').transform(lambda x: ', '.join(x))\n",
    "    aux['word_stemmed'] = aux['word'].apply(lambda x : stemmer.stem(x.split(',')[0]))\n",
    "    aux.index = aux['word_stemmed']\n",
    "    del aux['word_stemmed']\n",
    "    my_dict = aux.to_dict('dict')['word']\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary_all_words_unstemmed = buffer_stemmisation_keywords(split_dataset_into_words(df['Consumer_complaint_narrative']))\n",
    "\n",
    "# Dictionnary de-duplicated\n",
    "for key, value in dictionnary_all_words_unstemmed.items():\n",
    "    new_value = value.replace(\",\", \"\")\n",
    "    new_value = list(set(value.split()))\n",
    "    new_value = list(set(map(lambda each:each.strip(\",\"), new_value)))\n",
    "    dictionnary_all_words_unstemmed[key]=new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary_all_words_unstemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='BLUE'>FEATURE ENGINEERING</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Count Vectors as features\n",
    "\n",
    "2.2 TF-IDF Vectors as features\n",
    "- --- Word level\n",
    "- --- N-Gram level\n",
    "- --- Character level\n",
    "\n",
    "2.3 Word Embeddings as features\n",
    "\n",
    "2.4 Text / NLP based features\n",
    "\n",
    "2.5 Topic Models as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different types of **word embeddings** can be broadly classified into two categories-\n",
    "\n",
    "- **Frequency based Embedding**\n",
    "        - Count Vector\n",
    "        - TF-IDF Vector\n",
    "        - Co-Occurrence Matrix with a fixed context window (with SVD)\n",
    "- **Prediction based Embedding**\n",
    "        - CBOW (Continuous Bag of words)\n",
    "        - Skip – Gram model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Count Vectors as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count Vector is a matrix notation of the dataset in which every row represents a document from the corpus, every column represents a term from the corpus, and every cell represents the frequency count of a particular term in a particular document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['Consumer_complaint_narrative'], df['Product'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(df['Consumer_complaint_narrative'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 TF-IDF Vectors as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. **Word Level TF-IDF**: Matrix representing tf-idf scores of every term in different documents\n",
    "\n",
    "b. **N-gram Level TF-IDF**: N-grams are the combination of N terms together. This Matrix representing tf-idf scores of N-grams\n",
    "\n",
    "c. **Character Level TF-IDF**: Matrix representing tf-idf scores of character level n-grams in the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most often **term-frequency** alone is **not** a good measure of the **importance of a word/term to a document's topic**.  Very common words like \"the\", \"a\", \"to\" are almost always the terms with the **highest frequency in the text**. Thus, having a high raw count of the number of times a term appears in a document does not necessarily mean that the corresponding word is more important. Furtermore, longer documents could have high frequency of terms that do not correlate with the document topic, but instead occur with high numbers solely due to the length of the document.\n",
    "\n",
    "To circumvent the limination of term-frequency, we often normalize it by the **inverse document frequency (idf)**.  This results in the **term frequency-inverse document frequency (tf-idf)** matrix.  The **inverse document frequency is a measure of how much information the word provides, that is, whether the term is common or rare across all documents in the corpus**.  We can give a formal defintion of the inverse-document-frequency by letting $\\mathcal{D}$ be the corpus or the set of all documents and $N$ is the number of documents in the corpus and $N_{t,D}$ be the number of documents that contain the term $t$ then, \n",
    "\n",
    "$$idf(t,\\mathcal{D}) \\, = \\,  \\log\\left(\\frac{N_{\\mathcal{D}}}{1 + N_{t,\\mathcal{D}}}\\right) \\, = \\, -  \\log\\left(\\frac{1 + N_{t,\\mathcal{D}}}{N_{\\mathcal{D}}}\\right) $$\n",
    "\n",
    "The reason for the presence of the $1$ is for smoothing.  Without it, if the term/word did not appear in any training documents, then its inverse-document-frequency would be $idf(t,\\mathcal{D}) = \\infty$.  However, with the presense of the $1$ it will now have $idf(t,\\mathcal{D}) = 0$.\n",
    "\n",
    "\n",
    "Now we can formally defined the term frequnecy-inverse document frequency as a normalized version of term-frequency,\n",
    "\n",
    "\n",
    "$$\\text{tf-idf}(t,d) \\, = \\, tf(t,d) \\cdot idf(t,\\mathcal{D}) $$\n",
    "\n",
    "Like the term-frequency, the term frequency-inverse document frequency is a sparse matrix, where again, each row is a document in our training corpus ($\\mathcal{D}$) and each column corresponds to a term/word in the bag-of-words list.\n",
    "_________________________________________\n",
    "**EXAMPLE:**\n",
    "\n",
    "**from** sklearn.feature_extraction.text **import** TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(**sublinear_tf**=True, **min_df**=5, **norm**='l2', **encoding**='latin-1', **ngram_range**=(1, 2), **stop_words**='english')\n",
    "\n",
    "features = tfidf.fit_transform(df['text']).toarray()\n",
    "labels = df.category_id\n",
    "_________________________________________\n",
    "\n",
    "- **sublinear_df** is set to True to use a logarithmic form for frequency.\n",
    "- **min_df** is the minimum numbers of documents a word must be present in to be kept.\n",
    "- **norm** is set to l2, to ensure all our feature vectors have a euclidian norm of 1.\n",
    "- **ngram_range** is set to (1, 2) to indicate that we want to consider both unigrams and bigrams.\n",
    "- **stop_words** is set to \"english\" to remove all common pronouns (\"a\", \"the\", ...) to reduce the number of noisy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(trainDF['text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(trainDF['text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term-frequency is a **sparse matrix** where **each row is a document in our training corpus** ($\\mathcal{D}$) and each **column corresponds to a term/word in the bag-of-words list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- Size of the matrix is', xvalid_tfidf.shape, 'as we passed 5,000 words and we have 1725 customer comments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Here is my bag of words:', tfidf_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of my bag of words:', len(tfidf_vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "features = tfidf.fit_transform(df.Consumer_complaint_narrative).toarray()\n",
    "labels = df.category_id\n",
    "\n",
    "print('- Size of the matrix is', features.shape)\n",
    "print('- Each of', features.shape[0], 'consumer complaint narratives is represented by', features.shape[1], 'features, representing the tf-idf score for different unigrams and bigrams.')\n",
    "print('-', features.shape[0], 'is the # of document / complaint and', features.shape[1], 'is my bag of words containing unigram and bigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term-frequency is a **sparse matrix** where **each row is a document in our training corpus** ($\\mathcal{D}$) and each **column corresponds to a term/word in the bag-of-words list**\n",
    "\n",
    "- **sklearn.feature_selection.chi2** to find the terms that are the most correlated with each of the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "N = 2\n",
    "for Product, category_id in sorted(category_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}':\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n       . {}\".format('\\n       . '.join(unigrams[-N:])))\n",
    "    print(\"  . Most correlated bigrams:\\n       . {}\".format('\\n       . '.join(bigrams[-N:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A word embedding is a **form of representing words and documents** using a **dense vector representation**. The position of a word within the vector space is learned from text and is based on the **words that surround the word** when it is used. Word embeddings can be trained using the input corpus **itself** or can **be generated using pre-trained word embeddings** such as **Glove**, **FastText**, and **Word2Vec**. Any one of them can be downloaded and **used as transfer learning**. \n",
    "\n",
    "Four essential steps:\n",
    "- Loading the pretrained word embeddings\n",
    "- Creating a tokenizer object\n",
    "- Transforming text documents to sequence of tokens and pad them\n",
    "- Create a mapping of token and their respective embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.slideshare.net/PyData/sujit-pal-applying-the-fourstep-embed-encode-attend-predict-framework-to-predict-document-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('data/wiki-news-300d-1M.vec')):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(trainDF['text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Text / NLP based features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. **Word Count of the documents** – total number of words in the documents\n",
    "- 2. **Character Count of the documents** – total number of characters in the documents\n",
    "- 3. **Average Word Density of the documents** – average length of the words used in the documents\n",
    "- 4. **Puncutation Count in the Complete Essay** – total number of punctuation marks in the documents\n",
    "- 5. **Upper Case Count in the Complete Essay** – total number of upper count words in the documents\n",
    "- 6. **Title Word Count in the Complete Essay** – total number of proper case (title) words in the documents\n",
    "- 7. **Frequency distribution of Part of Speech Tags:**\n",
    "    - Noun Count\n",
    "    - Verb Count\n",
    "    - Adjective Count\n",
    "    - Adverb Count\n",
    "    - Pronoun Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF['char_count'] = trainDF['text'].apply(len)\n",
    "trainDF['word_count'] = trainDF['text'].apply(lambda x: len(x.split()))\n",
    "trainDF['word_density'] = trainDF['char_count'] / (trainDF['word_count']+1)\n",
    "trainDF['punctuation_count'] = trainDF['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "trainDF['title_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "trainDF['upper_case_word_count'] = trainDF['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "trainDF['noun_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "trainDF['verb_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "trainDF['adj_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "trainDF['adv_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "trainDF['pron_count'] = trainDF['text'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Topic Models as features (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA Model\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "X_topics = lda_model.fit_transform(xtrain_count)\n",
    "topic_word = lda_model.components_ \n",
    "vocab = count_vect.get_feature_names()\n",
    "\n",
    "# view the topic models\n",
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='BLUE'>MODEL BUILDING</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes Classifier\n",
    "- Linear Classifier\n",
    "- Support Vector Machine\n",
    "- Bagging Models\n",
    "- Boosting Models\n",
    "- Shallow Neural Networks\n",
    "- Deep Neural Networks\n",
    "- Convolutional Neural Network (CNN)\n",
    "- Long Short Term Modelr (LSTM)\n",
    "- Gated Recurrent Unit (GRU)\n",
    "- Bidirectional RNN\n",
    "- Recurrent Convolutional Neural Network (RCNN)\n",
    "- Other Variants of Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "\n",
    "One of the most basic models for text classification is the <a href=\"https://en.wikipedia.org/wiki/Naive_Bayes_classifier\">Naive Bayes model</a>. The Naive Bayes classification model predicts the document topic, $y = \\{C_{1},C_{2},\\ldots, C_{20}\\}$ where $C_{k}$ is the class or topic based on the document feactures $\\textbf{x} \\in \\mathbb{N}^{p}$,  and $p$ is the number of terms in our bag-of-words list.  The feature vector,\n",
    "\n",
    "$$\\textbf{x} \\, = \\, \\left[ x_{1}, x_{2}, \\ldots , x_{p} \\right] $$\n",
    "\n",
    "contains counts $x_{i}$ for the $\\text{tf-idf}$ value of the i-th term in our bag-of-words list.  Using <a href=\"https://en.wikipedia.org/wiki/Bayes%27_theorem\">Bayes Theorem</a> we can develop a model to predict the topic class  ($C_{k}$) of a document from its feature vector $\\textbf{x}$,\n",
    "\n",
    "$$P\\left(C_{k} \\, \\vert \\, x_{1}, \\ldots , x_{p} \\right) \\; = \\; \\frac{P\\left(x_{1}, \\ldots, x_{p} \\, \\vert \\, C_{k} \\right)P(C_{k})}{P\\left(x_{1}, \\ldots, x_{p} \\right)}$$\n",
    "\n",
    "The Naive Bayes model makes the \"Naive\" assumption the probability of each term's $\\text{tf-idf}$ is **conditionally independent** of every other term.  This reduces our **conditional probability function** to the product,\n",
    "\n",
    "$$ P\\left(x_{1}, \\ldots, x_{p} \\, \\vert \\, C_{k} \\right) \\; = \\; \\Pi_{i=1}^{p} P\\left(x_{i} \\, \\vert \\, C_{k} \\right)$$\n",
    "\n",
    "Subsequently Bayes' theorem for our classification problem becomes,\n",
    "\n",
    "$$P\\left(C_{k} \\, \\vert \\, x_{1}, \\ldots , x_{p} \\right) \\; = \\; \\frac{ P(C_{k}) \\, \\Pi_{i=1}^{p} P\\left(x_{i} \\, \\vert \\, C_{k} \\right)}{P\\left(x_{1}, \\ldots, x_{p} \\right)}$$\n",
    "\n",
    "\n",
    "Since the denominator is independent of the class ($C_{k}$) we can use a <a href=\"https://en.wikipedia.org/wiki/Maximum_a_posteriori\">Maxmimum A Posteriori</a> method to estimate the document topic , \n",
    "\n",
    "$$ \\hat{y} \\, = \\, \\text{arg max}_{k}\\;  P(C_{k}) \\,  \\Pi_{i=1}^{p} P\\left(x_{i} \\, \\vert \\, C_{k} \\right)$$ \n",
    "\n",
    "\n",
    "The **prior**, $P(C_{k}),$ is often taken to be the relative frequency of the class in the training corpus, while the form of the conditional distribution $P\\left(x_{i} \\, \\vert \\, C_{k} \\right)$ is a choice of the modeler and determines the type of Naive Bayes classifier. \n",
    "\n",
    "\n",
    "We will use a <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB\">multinomial Naive Bayes</a> model which works well when our features are discrete variables such as those in our $\\text{tf-idf}$ matrix.  In the multinomial Naive Bayes model the conditional probability takes the form,\n",
    "\n",
    "\n",
    "$$ P\\left(x_{1}, \\ldots, x_{p} \\, \\vert \\, C_{k} \\right) \\, = \\, \\frac{\\left(\\sum_{i=1}^{p} x_{i}\\right)!}{\\Pi_{i=1}^{p} x_{i}!}  \\Pi_{i=1}^{p} p_{k,i}^{x_{i}}$$\n",
    "\n",
    "\n",
    "where $p_{k,i}$ is the probability that the $k$-th class will have the $i$-th bag-of-words term in its feature vector. This leads to our **posterior distribution** having the functional form,\n",
    "\n",
    "$$P\\left(C_{k} \\, \\vert \\, x_{1}, \\ldots , x_{p} \\right) \\; = \\; \\frac{ P(C_{k})}{P\\left(x_{1}, \\ldots, x_{p} \\right)} \\, \\frac{\\left(\\sum_{i=1}^{p} x_{i}\\right)!}{\\Pi_{i=1}^{p} x_{i}!}  \\Pi_{i=1}^{p} p_{k,i}^{x_{i}}$$\n",
    "\n",
    "\n",
    "\n",
    "We can instantiate a multinomial Naive Bayes classifier using the Scikit-learn library and fit it to our  $\\text{tf-idf}$ matrix using the commands,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes on Count Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Word Level TF IDF Vectors\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Naive Bayes on Character Level TF IDF Vectors\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"NB, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at my dataframe\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainDF['text'], trainDF['label'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "mod = MultinomialNB()\n",
    "clf = mod.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_test_tf = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_tf)\n",
    "\n",
    "predicted = mod.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- A -- **Accuracy** - Accuracy is the most intuitive performance measure and it is simply **a ratio of correctly predicted observation to the total observations.** One may think that, **if we have high accuracy then our model is best**. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, you have to look at other parameters to evaluate the performance of your model. **For our model, we have got 0.803 which means our model is approx. 80% accurate.**\n",
    "\n",
    "**Accuracy = TP+TN/TP+FP+FN+TN**\n",
    "\n",
    "-- B -- **Precision** - Precision is the ratio of **correctly predicted positive observations to the total predicted positive observations.** The question that this metric answer is of **all passengers that labeled as survived, how many actually survived?** High precision relates to the low false positive rate. We have got 0.788 precision which is pretty good.\n",
    "\n",
    "**Precision = TP/TP+FP**\n",
    "\n",
    "-- C -- **Recall (Sensitivity)** - Recall is the **ratio of correctly predicted positive observations to the all observations in actual class - yes**. The question recall answers is: **Of all the passengers that truly survived, how many did we label?** We have got recall of 0.631 which is good for this model as it’s above 0.5.\n",
    "\n",
    "**Recall = TP/TP+FN**\n",
    "\n",
    "-- D -- **F1 score** - F1 Score is the **weighted average of Precision and Recall.** Therefore, this score takes both false positives and false negatives into account. Intuitively it is not as easy to understand as accuracy, but F1 is usually more useful than accuracy, especially if you have an uneven class distribution. Accuracy works best if false positives and false negatives have similar cost. If the cost of false positives and false negatives are very different, it’s better to look at both Precision and Recall. In our case, F1 score is 0.701.\n",
    "\n",
    "**F1 Score = 2*(Recall * Precision) / (Recall + Precision)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prediction\n",
    "print(clf.predict(count_vect.transform([\"\"\" spent 3 days on the phone with countless \"agents\" - most of that time trying to get each one to understand what I wanted - simply wanted to change my email address in my account. Based on the terrible telephone service I assume they are all located in South America where it is known to be poor quality phone service. Spent 15 - 25 minutes just getting them to understand what the problem was. Ended up having to create a new account losing my entire order history. This has to be the worse phone customer service out there!\"\"\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Linear Classifier / Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stlong0521.github.io/20160228%20-%20Logistic%20Regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><p>The generative classification model, such as Naive Bayes, tries to learn the probabilities and then predict by using Bayes rules to calculate the posterior, <span class=\"math\">\\(p(y|\\textbf{x})\\)</span>. However, discrimitive classifiers model the posterior directly. As one of the most popular discrimitive classifiers, logistic regression directly models the linear decision boundary.</p>\n",
    "<h3>Binary Logistic Regression Classifier<sup id=\"fnref:1\"><a class=\"footnote-ref\" href=\"#fn:1\" rel=\"footnote\">1</a></sup></h3>\n",
    "<p>Let us start with the binary case. For an M-dimensional feature vector <span class=\"math\">\\(\\textbf{x}=[x_1,x_2,...,x_M]^T\\)</span>, the posterior probability of class <span class=\"math\">\\(y\\in\\{\\pm{1}\\}\\)</span> given <span class=\"math\">\\(\\textbf{x}\\)</span> is assumed to satisfy\n",
    "</p>\n",
    "<div class=\"math\">\\begin{equation}\n",
    "\\ln{\\frac{p(y=1|\\textbf{x})}{p(y=-1|\\textbf{x})}}=\\textbf{w}^T\\textbf{x},\n",
    "\\end{equation}</div>\n",
    "<p>\n",
    "where <span class=\"math\">\\(\\textbf{w}=[w_1,w_2,...,w_M]^T\\)</span> is the weighting vector to be learned. Given the constraint that <span class=\"math\">\\(p(y=1|\\textbf{x})+p(y=-1|\\textbf{x})=1\\)</span>, it follows that\n",
    "</p>\n",
    "<div class=\"math\">\\begin{equation} \\label{Eqn:Prob_Binary}\n",
    "p(y|\\textbf{x})=\\frac{1}{1+\\exp(-y\\textbf{w}^T\\textbf{x})}=\\sigma(y\\textbf{w}^T\\textbf{x}),\n",
    "\\end{equation}</div>\n",
    "<p>\n",
    "in which we can observe the logistic sigmoid function <span class=\"math\">\\(\\sigma(a)=\\frac{1}{1+\\exp(-a)}\\)</span>.</p>\n",
    "<p>Based on the assumptions above, the weighting vector, <span class=\"math\">\\(\\textbf{w}\\)</span>, can be learned by maximum likelihood estimation (MLE). More specifically, given training data set <span class=\"math\">\\(\\mathcal{D}=\\{(\\textbf{x}_1,y_1),(\\textbf{x}_2,y_2),...,(\\textbf{x}_N,y_N)\\}\\)</span>,\n",
    "</p>\n",
    "<div class=\"math\">\\begin{align}\n",
    "\\begin{aligned}\n",
    "\\textbf{w}^*&amp;=\\max_{\\textbf{w}}{\\mathcal{L}(\\textbf{w})}\\\\\n",
    "&amp;=\\max_{\\textbf{w}}{\\sum_{i=1}^N\\ln{{p(y_i|\\textbf{x}_i)}}}\\\\\n",
    "&amp;=\\max_{\\textbf{w}}{\\sum_{i=1}^N{\\ln{\\frac{1}{1+\\exp(-y_i\\textbf{w}^T\\textbf{x}_i)}}}}\\\\\n",
    "&amp;=\\min_{\\textbf{w}}{\\sum_{i=1}^N{\\ln{(1+\\exp(-y_i\\textbf{w}^T\\textbf{x}_i))}}}.\n",
    "\\end{aligned}\n",
    "\\end{align}</div>\n",
    "<p>\n",
    "We have a convex objective function here, and we can calculate the optimal solution by applying gradient descent. The gradient can be drawn as\n",
    "</p>\n",
    "<div class=\"math\">\\begin{align}\n",
    "\\begin{aligned}\n",
    "\\nabla{\\mathcal{L}(\\textbf{w})}&amp;=\\sum_{i=1}^N{\\frac{-y_i\\textbf{x}_i\\exp(-y_i\\textbf{w}^T\\textbf{x}_i)}{1+\\exp(-y_i\\textbf{w}^T\\textbf{x}_i)}}\\\\\n",
    "&amp;=-\\sum_{i=1}^N{y_i\\textbf{x}_i(1-p(y_i|\\textbf{x}_i))}.\n",
    "\\end{aligned}\n",
    "\\end{align}</div>\n",
    "<p>\n",
    "Then, we can learn the optimal <span class=\"math\">\\(\\textbf{w}\\)</span> by starting with an initial <span class=\"math\">\\(\\textbf{w}_0\\)</span> and iterating as follows:\n",
    "</p>\n",
    "<div class=\"math\">\\begin{equation} \\label{Eqn:Iteration_Binary}\n",
    "\\textbf{w}_{t+1}=\\textbf{w}_{t}-\\eta_t\\nabla{\\mathcal{L}(\\textbf{w})},\n",
    "\\end{equation}</div>\n",
    "<p>\n",
    "where <span class=\"math\">\\(\\eta_t\\)</span> is the learning step size. It can be invariant to time, but time-varying step sizes could potential reduce the convergence time, e.g., setting <span class=\"math\">\\(\\eta_t\\propto{1/\\sqrt{t}}\\)</span> such that the step size decreases with an increasing time <span class=\"math\">\\(t\\)</span>.</p>\n",
    "<h3>Multiclass Logistic Regression Classifier<sup id=\"fnref:1\"><a class=\"footnote-ref\" href=\"#fn:1\" rel=\"footnote\">1</a></sup></h3>\n",
    "<p>When it is generalized to multiclass case, the logistic regression model needs to adapt accordingly. Now we have <span class=\"math\">\\(K\\)</span> possible classes, that is, <span class=\"math\">\\(y\\in\\{1,2,..,K\\}\\)</span>. It is assumed that the posterior probability of class <span class=\"math\">\\(y=k\\)</span> given <span class=\"math\">\\(\\textbf{x}\\)</span> follows\n",
    "</p>\n",
    "<div class=\"math\">\\begin{equation}\n",
    "\\ln{p(y=k|\\textbf{x})}\\propto\\textbf{w}_k^T\\textbf{x},\n",
    "\\end{equation}</div>\n",
    "<p>\n",
    "where <span class=\"math\">\\(\\textbf{w}_k\\)</span> is a column weighting vector corresponding to class <span class=\"math\">\\(k\\)</span>. Considering all classes <span class=\"math\">\\(k=1,2,...,K\\)</span>, we would have a weighting matrix that includes all <span class=\"math\">\\(K\\)</span> weighting vectors. That is, <span class=\"math\">\\(\\textbf{W}=[\\textbf{w}_1,\\textbf{w}_2,...,\\textbf{w}_K]\\)</span>.\n",
    "Under the constraint\n",
    "</p>\n",
    "<div class=\"math\">\\begin{equation}\n",
    "\\sum_{k=1}^K{p(y=k|\\textbf{x})}=1,\n",
    "\\end{equation}</div>\n",
    "<p>\n",
    "it then follows that\n",
    "</p>\n",
    "<div class=\"math\">\\begin{equation} \\label{Eqn:Prob_Multiple}\n",
    "p(y=k|\\textbf{x})=\\frac{\\exp(\\textbf{w}_k^T\\textbf{x})}{\\sum_{j=1}^K{\\exp(\\textbf{w}_j^T\\textbf{x})}}.\n",
    "\\end{equation}</div>\n",
    "<p>The weighting matrix, <span class=\"math\">\\(\\textbf{W}\\)</span>, can be similarly learned by maximum likelihood estimation (MLE). More specifically, given training data set <span class=\"math\">\\(\\mathcal{D}=\\{(\\textbf{x}_1,y_1),(\\textbf{x}_2,y_2),...(\\textbf{x}_N,y_N)\\}\\)</span>,\n",
    "</p>\n",
    "<div class=\"math\">\\begin{align}\n",
    "\\begin{aligned}\n",
    "\\textbf{W}^*&amp;=\\max_{\\textbf{W}}{\\mathcal{L}(\\textbf{W})}\\\\\n",
    "&amp;=\\max_{\\textbf{W}}{\\sum_{i=1}^N\\ln{{p(y_i|\\textbf{x}_i)}}}\\\\\n",
    "&amp;=\\max_{\\textbf{W}}{\\sum_{i=1}^N{\\ln{\\frac{\\exp(\\textbf{w}_{y_i}^T\\textbf{x})}{\\sum_{j=1}^K{\\exp(\\textbf{w}_j^T\\textbf{x})}}}}}.\n",
    "\\end{aligned}\n",
    "\\end{align}</div>\n",
    "<p>\n",
    "The gradient of the objective function with respect to each <span class=\"math\">\\(\\textbf{w}_k\\)</span> can be calculated as\n",
    "</p>\n",
    "<div class=\"math\">\\begin{align}\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial{\\mathcal{L}(\\textbf{W})}}{\\partial{\\textbf{w}_k}}&amp;=\\sum_{i=1}^N{\\textbf{x}_i\\left(I(y_i=k)-\\frac{\\exp(\\textbf{w}_k^T\\textbf{x})}{\\sum_{j=1}^K{\\exp(\\textbf{w}_j^T\\textbf{x})}}\\right)}\\\\\n",
    "&amp;=\\sum_{i=1}^N{\\textbf{x}_i(I(y_i=k)-p(y_i=k|\\textbf{x}_i))},\n",
    "\\end{aligned}\n",
    "\\end{align}</div>\n",
    "<p>\n",
    "where <span class=\"math\">\\(I(\\cdot)\\)</span> is a binary indicator function. Applying gradient descent, the optimal solution can be obtained by iterating as follows:\n",
    "</p>\n",
    "<div class=\"math\">\\begin{equation}\\label{Eqn:Iteration_Multiple}\n",
    "\\textbf{w}_{k,t+1}=\\textbf{w}_{k,t}+\\eta_{t}\\frac{\\partial{\\mathcal{L}(\\textbf{W})}}{\\partial{\\textbf{w}_k}}.\n",
    "\\end{equation}</div>\n",
    "<p>\n",
    "Note that we have \"<span class=\"math\">\\(+\\)</span>\" instead of \"<span class=\"math\">\\(-\\)</span>\", because the maximum likelihood estimation in the binary case is eventually converted to a minimization problem, while here we keep performing maximization.</p>\n",
    "<h3>How to Perform Predictions?</h3>\n",
    "<p>Once the optimal weights are learned from the logistic regression model, for any new feature vector <span class=\"math\">\\(\\textbf{x}\\)</span>, we can easily calculate the probability that it is associated to each class label <span class=\"math\">\\(k\\)</span> in the binary case in the multiclass case. With the probabilities for each class label available, we can then perform:</p>\n",
    "<ul>\n",
    "<li>a hard decision by identifying the class label with the highest probability, or</li>\n",
    "<li>a soft decision by showing the top <span class=\"math\">\\(k\\)</span> most probable class labels with their corresponding probabilities.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Classifier on Count Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "print(\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Word Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print(\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# Linear Classifier on Character Level TF IDF Vectors\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "print(\"LR, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Implementing a SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://svivek.com/teaching/machine-learning/fall2018/slides/svm/svm-sgd.pdf\n",
    "# https://medium.com/deep-math-machine-learning-ai/chapter-3-support-vector-machine-with-math-47d6193c82be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# SVM on Ngram Level TF IDF Vectors\n",
    "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "print(\"SVM, N-Gram Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> _ = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
    ">>> predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
    ">>> np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Bagging Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF on Count Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "print \"RF, Count Vectors: \", accuracy\n",
    "\n",
    "# RF on Word Level TF IDF Vectors\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "print \"RF, WordLevel TF-IDF: \", accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extereme Gradient Boosting on Count Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "print(\"Xgb, Count Vectors: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "print(\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "print(\"Xgb, CharLevel Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Shallow Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_architecture(input_size):\n",
    "    # create input layer \n",
    "    input_layer = layers.Input((input_size, ), sparse=True)\n",
    "    \n",
    "    # create hidden layer\n",
    "    hidden_layer = layers.Dense(100, activation=\"relu\")(input_layer)\n",
    "    \n",
    "    # create output layer\n",
    "    output_layer = layers.Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    classifier = models.Model(inputs = input_layer, outputs = output_layer)\n",
    "    classifier.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    return classifier \n",
    "\n",
    "classifier = create_model_architecture(xtrain_tfidf_ngram.shape[1])\n",
    "accuracy = train_model(classifier, xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram, is_neural_net=True)\n",
    "print(\"NN, Ngram Level TF IDF Vectors\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.1 Convolutional Neural Network [Deep Neural Networks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"cnn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Add the pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_cnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"CNN, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.2 Recurrent Neural Network – LSTM [Deep Neural Networks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_lstm():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.LSTM(100)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rnn_lstm()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-LSTM, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.3 Recurrent Neural Network – GRU [Deep Neural Networks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_gru():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the GRU Layer\n",
    "    lstm_layer = layers.GRU(100)(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rnn_gru()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-GRU, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.4 Bidirectional RNN [Deep Neural Networks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bidirectional_rnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "\n",
    "    # Add the LSTM Layer\n",
    "    lstm_layer = layers.Bidirectional(layers.GRU(100))(embedding_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(lstm_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_bidirectional_rnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"RNN-Bidirectional, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7.5 Recurrent Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hierarichial Attention Networks\n",
    "- Sequence to Sequence Models with Attention\n",
    "- Bidirectional Recurrent Convolutional Neural Networks\n",
    "- CNNs and RNNs with more number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rcnn():\n",
    "    # Add an Input Layer\n",
    "    input_layer = layers.Input((70, ))\n",
    "\n",
    "    # Add the word embedding Layer\n",
    "    embedding_layer = layers.Embedding(len(word_index) + 1, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
    "    embedding_layer = layers.SpatialDropout1D(0.3)(embedding_layer)\n",
    "    \n",
    "    # Add the recurrent layer\n",
    "    rnn_layer = layers.Bidirectional(layers.GRU(50, return_sequences=True))(embedding_layer)\n",
    "    \n",
    "    # Add the convolutional Layer\n",
    "    conv_layer = layers.Convolution1D(100, 3, activation=\"relu\")(embedding_layer)\n",
    "\n",
    "    # Add the pooling Layer\n",
    "    pooling_layer = layers.GlobalMaxPool1D()(conv_layer)\n",
    "\n",
    "    # Add the output Layers\n",
    "    output_layer1 = layers.Dense(50, activation=\"relu\")(pooling_layer)\n",
    "    output_layer1 = layers.Dropout(0.25)(output_layer1)\n",
    "    output_layer2 = layers.Dense(1, activation=\"sigmoid\")(output_layer1)\n",
    "\n",
    "    # Compile the model\n",
    "    model = models.Model(inputs=input_layer, outputs=output_layer2)\n",
    "    model.compile(optimizer=optimizers.Adam(), loss='binary_crossentropy')\n",
    "    \n",
    "    return model\n",
    "\n",
    "classifier = create_rcnn()\n",
    "accuracy = train_model(classifier, train_seq_x, train_y, valid_seq_x, is_neural_net=True)\n",
    "print(\"CNN, Word Embeddings\",  accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='BLUE'>EXPLAIN MODELS</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextExplainer: debugging black-box text classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html\n",
    "\n",
    "https://eli5.readthedocs.io/en/latest/tutorials/black-box-text-classifiers.html#example-problem-lsa-svm-for-20-newsgroups-dataset\n",
    "\n",
    "**Goal:** explain predictions of arbitrary classifiers, including text classifiers (when it is hard to get exact mapping between model coefficients and text features, e.g. if there is dimension reduction involved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example problem: LSA+SVM for 20 Newsgroups dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']\n",
    "twenty_train = fetch_20newsgroups(\n",
    "    subset='train',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=('headers', 'footers'),\n",
    ")\n",
    "twenty_test = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    remove=('headers', 'footers'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "vec = TfidfVectorizer(min_df=3, stop_words='english',\n",
    "                      ngram_range=(1, 2))\n",
    "\n",
    "# The dimension of the input documents is reduced to 100, and then a kernel SVM is used to classify the documents.\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "lsa = make_pipeline(vec, svd)\n",
    "\n",
    "clf = SVC(C=150, gamma=2e-2, probability=True)\n",
    "pipe = make_pipeline(lsa, clf)\n",
    "pipe.fit(twenty_train.data, twenty_train.target)\n",
    "pipe.score(twenty_test.data, twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(doc):\n",
    "    y_pred = pipe.predict_proba([doc])[0]\n",
    "    for target, prob in zip(twenty_train.target_names, y_pred):\n",
    "        print(\"{:.3f} {}\".format(prob, target))\n",
    "\n",
    "doc = twenty_test.data[0]\n",
    "\n",
    "print(twenty_test.data[0])\n",
    "print('------------------------------------ What is the prediction?-------------------------------------------------------')\n",
    "print_prediction(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextExplainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a TextExplainer instance, \n",
    "2. ... then pass the document to explain and a black-box classifier (a function which returns probabilities) to the fit() method, \n",
    "3. ... then check the explanation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "\n",
    "doc = twenty_test.data[0]\n",
    "\n",
    "te = TextExplainer(random_state=42)\n",
    "te.fit(doc, pipe.predict_proba)\n",
    "te.show_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why it works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation makes sense - we expect reasonable classifier to **take highlighted words in account**. But how can we be sure this is **how the pipeline works**, not just a nice-looking lie? \n",
    "\n",
    "A simple **sanity check** is to **remove or change the highlighted words**, to confirm that **they change the outcome**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "doc2 = re.sub(r'(recall|kidney|stones|medication|pain|tech)', '', doc, flags=re.I)\n",
    "print_prediction(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicted probabilities changed a lot indeed.**\n",
    "\n",
    "And in fact, TextExplainer did something similar to get the explanation. TextExplainer generated a lot of texts similar to the document (by removing some of the words), and then trained a white-box classifier which predicts the output of the black-box classifier (not the true labels!). The explanation we saw is for this white-box classifier.\n",
    "\n",
    "This approach follows the LIME algorithm; for text data the algorithm is actually pretty straightforward:\n",
    "\n",
    "- generate distorted versions of the text;\n",
    "- predict probabilities for these distorted texts using the black-box classifier;\n",
    "- train another classifier (one of those eli5 supports) which tries to predict output of a black-box classifier on these texts.\n",
    "\n",
    "The algorithm works because even though it could be hard or impossible to approximate a black-box classifier globally (for every possible text), approximating it in a small neighbourhood near a given text often works well, even with simple white-box classifiers.\n",
    "\n",
    "Generated samples (distorted texts) are available in samples_ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(te.samples_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default TextExplainer generates 5000 distorted texts (use n_samples argument to change the amount):\n",
    "len(te.samples_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing TextExplainer: classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "dtree.fit(te5.show_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_prediction_tree_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "te5 = TextExplainer(clf=DecisionTreeClassifier(max_depth=2), random_state=0)\n",
    "te5.fit(doc, pipe.predict_proba)\n",
    "print(te5.metrics_)\n",
    "te5.show_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So according to this tree if **“kidney” is not in the document** and **“pain” is not in the document** then the **probability of a document** belonging to **sci.med** drops to **0.65**. If at least one of these words remain sci.med probability stays** 0.9+.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 ways to interpretate NLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/makcedward/nlp/blob/master/sample/nlp-model_interpretation.ipynb\n",
    "\n",
    "**Goal**: want to know why we predict it wrongly\n",
    "\n",
    "**1 . Interpretability**\n",
    "- **Intrinsic**: We do not need to train another model to explain the target. For example, it is using decision tree or linear model\n",
    "- **Post hoc**: The model belongs to black-box model which we need to use another model to interpret it. \n",
    "\n",
    "**2. Approach**\n",
    "- **Model-specific**: Some tools are limited to specific model such as liner model and neural network model.\n",
    "- **Model-agnostic**: On the other hand, some tools able to explain any model by building write-box model. \n",
    "\n",
    "** 3. Level**\n",
    "- **Global**: Explain the overall model such as feature weight. This one give you a in general model behavior\n",
    "- **Local**: Explain the specific prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import IPython\n",
    "import xgboost\n",
    "\n",
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "print('ELI5 Version:', eli5.__version__)\n",
    "print('XGBoost Version:', xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train_raw_df = fetch_20newsgroups(subset='train')\n",
    "test_raw_df = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_raw_df.data\n",
    "y_train = train_raw_df.target\n",
    "\n",
    "x_test = test_raw_df.data\n",
    "y_test = test_raw_df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Logistic Regression', 'Random Forest', 'XGBoost Classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(names, x, y):\n",
    "    pipelines = []\n",
    "    vec = TfidfVectorizer()\n",
    "    vec.fit(x)\n",
    "\n",
    "    for name in names:\n",
    "        print('train %s' % name)\n",
    "        \n",
    "        if name == 'Logistic Regression':\n",
    "            estimator = LogisticRegression(solver='newton-cg', n_jobs=-1)\n",
    "            pipeline = make_pipeline(vec, estimator)\n",
    "        elif name == 'Random Forest':\n",
    "            estimator = RandomForestClassifier(n_jobs=-1)\n",
    "            pipeline = make_pipeline(vec, estimator)\n",
    "        elif name == 'XGBoost Classifier':\n",
    "            estimator = XGBClassifier()\n",
    "            pipeline = make_pipeline(vec, estimator)\n",
    "            \n",
    "        pipeline.fit(x, y)\n",
    "        pipelines.append({\n",
    "            'name': name,\n",
    "            'pipeline': pipeline\n",
    "        })\n",
    "        \n",
    "    return pipelines, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines, vec = build_model(names, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ELI5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. - ELI5 - Global Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipeline in pipelines:\n",
    "    print('Estimator: %s' % (pipeline['name']))\n",
    "    labels = pipeline['pipeline'].classes_.tolist()\n",
    "    \n",
    "    if pipeline['name'] in ['Logistic Regression', 'Random Forest']:\n",
    "        estimator = pipeline['pipeline']\n",
    "    elif pipeline['name'] == 'XGBoost Classifier':\n",
    "        estimator = pipeline['pipeline'].steps[1][1].get_booster()\n",
    "#     Not support Keras\n",
    "#     elif pipeline['name'] == 'keras':\n",
    "#         estimator = pipeline['pipeline']\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    IPython.display.display(\n",
    "        eli5.show_weights(estimator=estimator, top=10, target_names=labels, vec=vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. - ELI5 - Local Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sample = 1\n",
    "sample_ids = [random.randint(0, len(x_test) -1 ) for p in range(0, number_of_sample)]\n",
    "\n",
    "for idx in sample_ids:\n",
    "    print('Index: %d' % (idx))\n",
    "#     print('Index: %d, Feature: %s' % (idx, x_test[idx]))\n",
    "    for pipeline in pipelines:\n",
    "        print('-' * 50)\n",
    "        print('Estimator: %s' % (pipeline['name']))\n",
    "        \n",
    "        print('True Label: %s, Predicted Label: %s' % (y_test[idx], pipeline['pipeline'].predict([x_test[idx]])[0]))\n",
    "        labels = pipeline['pipeline'].classes_.tolist()\n",
    "  \n",
    "        if pipeline['name'] in ['Logistic Regression', 'Random Forest']:\n",
    "            estimator = pipeline['pipeline'].steps[1][1]\n",
    "        elif pipeline['name'] == 'XGBoost Classifier':\n",
    "            estimator = pipeline['pipeline'].steps[1][1].get_booster()\n",
    "        #     Not support Keras\n",
    "#         elif pipeline['name'] == 'Keras':\n",
    "#             estimator = pipeline['pipeline'].model\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        IPython.display.display(\n",
    "            eli5.show_prediction(estimator, x_test[idx], top=10, vec=vec, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LIME [2 independent examples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>1st example</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/emanceau/interpreting-machine-learning-lime-explainer/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains text from works of fiction written by spooky authors of the public domain:\n",
    "- Edgar Allan Poe (EAP)\n",
    "- HP Lovecraft (HPL)\n",
    "- Mary Wollstonecraft Shelley (MWS)\n",
    "\n",
    "The objective is to **accurately identify the author of the sentences in the test set**\n",
    "\n",
    "**Lime explainer mission** is to help human to **understand decisions made by machine learning**. Basically, lime explainer create **a local linear model** around the prediction and try to **explain factor influence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import ensemble, metrics, model_selection, naive_bayes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from lime import lime_text\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import itertools  \n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>Still, as I urged our leaving Ireland with suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>If a fire wanted fanning, it could readily be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>And when they had broken down the frail door t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>While I was thinking how I should possibly man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>I am not sure to what limit his knowledge may ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0  id02310  Still, as I urged our leaving Ireland with suc...\n",
       "1  id24541  If a fire wanted fanning, it could readily be ...\n",
       "2  id00134  And when they had broken down the frail door t...\n",
       "3  id27757  While I was thinking how I should possibly man...\n",
       "4  id04081  I am not sure to what limit his knowledge may ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explainer with basic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = ['EAP', 'HPL', 'MWS']\n",
    "cols_to_drop = ['id', 'text']\n",
    "train_X = train_df.drop(cols_to_drop+['author'], axis=1)\n",
    "\n",
    "## Prepare the data for modeling ###\n",
    "author_mapping_dict = {'EAP':0, 'HPL':1, 'MWS':2}\n",
    "train_y = train_df['author'].map(author_mapping_dict)\n",
    "train_id = train_df['id'].values\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(ngram_range=(1,5), analyzer='char')\n",
    "full_tfidf = tfidf_vec.fit_transform(train_df['text'].values.tolist() + test_df['text'].values.tolist())\n",
    "train_tfidf = tfidf_vec.transform(train_df['text'].values.tolist())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_tfidf, train_y, test_size=0.33, random_state=14)\n",
    "model_tf = naive_bayes.MultinomialNB()\n",
    "model_tf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_tf.predict(X_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "c_tf = make_pipeline(tfidf_vec, model_tf)\n",
    "\n",
    "split_expression = lambda s: re.split(r'\\W+', s)\n",
    "explainer = LimeTextExplainer(class_names=class_names, split_expression=split_expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = y_test.to_frame()\n",
    "comp['idx'] = comp.index.values\n",
    "comp['pred'] = y_pred\n",
    "comp.rename(columns={'author': 'real'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A --- True POE but classified in HPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_poe_hpl = comp[(comp.real ==0) & (comp.pred ==1)]\n",
    "wrong_poe_hpl.shape\n",
    "print(wrong_poe_hpl.idx)\n",
    "idx = wrong_poe_hpl.idx.iloc[1]\n",
    "\n",
    "print('We see that we got', len(wrong_poe_hpl.idx), 'as shown by the confusion matrix above')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tf.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = lambda doc: re.compile(r\"(?u)\\b\\w\\w+\\b\").findall(doc)\n",
    "explainer = LimeTextExplainer(class_names=class_names, split_expression=tokenizer)\n",
    "exp = explainer.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This error is created by the use of ancient greek words. Possible to improve the model ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = wrong_poe_hpl.idx.iloc[3]\n",
    "exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=2)\n",
    "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, very difficult case. Only three words > Not enough to properly classify. No improvement possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. --- True POE but classified in MWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_poe_mws = comp[(comp.real ==0) & (comp.pred ==2)]\n",
    "print(wrong_poe_mws.shape)\n",
    "idx = wrong_poe_mws.idx.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\n",
    "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, this text contains anaphora, possible to improve the model with anaphora feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = wrong_poe_mws.idx.iloc[18]\n",
    "exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\n",
    "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, probabilities (EAP and MWS) are very close. Possible to improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. --- True MWS but classified in HPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_mws_hpl = comp[(comp.real ==2) & (comp.pred ==1)]\n",
    "print(wrong_mws_hpl.shape)\n",
    "idx = wrong_mws_hpl.idx.iloc[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\n",
    "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, probabilities (HPL and MWS) are very close. Possible to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = wrong_mws_hpl.idx.iloc[5]\n",
    "exp = explainer_tf.explain_instance(train_df['text'][idx], c_tf.predict_proba, num_features=4, top_labels=3)\n",
    "exp.show_in_notebook(text=train_df['text'][idx], labels=(0,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, probabilities (EAP, HPL, MWS ) are all very close. Possible to improve the model (using repetition pattern ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>2nd example</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://marcotcr.github.io/lime/tutorials/Lime%20-%20basic%20usage%2C%20two%20class%20case.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st step : Fetching data, training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, we'll use a **2-class subset**: atheism and christianity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "class_names = ['atheism', 'christian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the **tfidf vectorizer**, commonly used for text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
    "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "test_vectors = vectorizer.transform(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's say we want to use **random forests for classification**. It's usually hard to understand what random forests are doing, especially with many trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf.fit(train_vectors, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = rf.predict(test_vectors)\n",
    "sklearn.metrics.f1_score(newsgroups_test.target, pred, average='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this classifier achieves a very high F score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd step : Explaining predictions using lime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lime explainers assume that **classifiers act on raw text**, but **sklearn classifiers** act on **vectorized representation of texts**. For this purpose, we use sklearn's pipeline, and implements predict_proba on raw_text lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "c = make_pipeline(vectorizer, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c.predict_proba([newsgroups_test.data[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an explainer object. We pass the class_names a an argument for prettier display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import re\n",
    "split_expression = lambda s: re.split(r'\\W+', s)\n",
    "explainer = LimeTextExplainer(class_names=class_names, split_expression=split_expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then generate an explanation with at most 6 features for an arbitrary document in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 83\n",
    "exp = explainer.explain_instance(newsgroups_test.data[idx], c.predict_proba, num_features=6)\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(christian) =', c.predict_proba([newsgroups_test.data[idx]])[0,1])\n",
    "print('True class: %s' % class_names[newsgroups_test.target[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier got this example right (it predicted atheism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The explanation is presented below as a list of weighted features\n",
    "\n",
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These weighted features are a linear model, which approximates the **behaviour of the random forest classifier in the vicinity of the test example**. Roughly, if we remove 'Posting' and 'Host' from the document , the prediction should move towards the opposite class (Christianity) by about 0.27 (the sum of the weights for both features). Let's see if this is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original prediction:', rf.predict_proba(test_vectors[idx])[0,1])\n",
    "tmp = test_vectors[idx].copy()\n",
    "tmp[0,vectorizer.vocabulary_['Posting']] = 0\n",
    "tmp[0,vectorizer.vocabulary_['Host']] = 0\n",
    "print('Prediction removing some features:', rf.predict_proba(tmp)[0,1])\n",
    "print('Difference:', rf.predict_proba(tmp)[0,1] - rf.predict_proba(test_vectors[idx])[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty close!\n",
    "**The words that explain the model around this document seem very arbitrary** - not much to do with either Christianity or Atheism.\n",
    "In fact, these are words that appear in the email headers (you will see this clearly soon), which **make distinguishing between the classes much easier.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Step: Visualizing explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=False)\n",
    "# exp.save_to_file('/tmp/oi.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how the words that affect the classifier the most are all in the email header.\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering documents using similarity features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/dipanjanS/practical-machine-learning-with-python/blob/master/bonus%20content/feature%20engineering%20text%20data/Feature%20Engineering%20Text%20Data%20-%20Traditional%20Strategies.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
